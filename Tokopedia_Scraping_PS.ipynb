{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfygREcfHhp7iVeksfGI2t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ajied21/Assignment-Guidance-Web-Scraping-Dibimbing/blob/master/Tokopedia_Scraping_PS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sebelum menjalankan perintah ya pastikan sudah menyiapkan bebrapa packages dan lainnya untuk melihat panduannya melalui : https://github.com/Ajied21/Assignment-Guidance-Web-Scraping-Dibimbing/blob/master/README.md"
      ],
      "metadata": {
        "id": "70lSBkCs4l2Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcXpBNNp17aP"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.by import By\n",
        "import pandas as pd\n",
        "import json\n",
        "from concurrent.futures import ThreadPoolExecutor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input URL untuk konsol PlayStation dan game PlayStation\n",
        "url_console_playstation = \"https://www.tokopedia.com/p/gaming/game-console/playstation\"\n",
        "url_game_playstation    = \"https://www.tokopedia.com/p/gaming/cd-game/cd-playstation\""
      ],
      "metadata": {
        "id": "XMjtQLFP3wRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi driver Chrome dengan opsi untuk memaksimalkan jendela browser\n",
        "def init_driver():\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument(\"--start-maximized\")\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "    return driver"
      ],
      "metadata": {
        "id": "tGxdRxFi3zjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk scraping data produk PlayStation dari halaman Tokopedia\n",
        "def playstation(url_PS):\n",
        "    click_pages = 5  # Jumlah halaman yang akan diklik\n",
        "    list_product_ps = []  # List untuk menyimpan data produk\n",
        "\n",
        "    if url_PS:  # Jika URL valid\n",
        "        driver = init_driver()  # Inisialisasi driver\n",
        "        driver.get(url_PS)  # Membuka URL\n",
        "\n",
        "        # Tunggu hingga elemen halaman muncul\n",
        "        WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CSS_SELECTOR, '#zeus-root')))\n",
        "        time.sleep(3)  # Tambahan jeda untuk memastikan halaman termuat\n",
        "\n",
        "        # Loop untuk melakukan scroll halaman\n",
        "        for ps in range(click_pages):\n",
        "            for page in range(18):\n",
        "                driver.execute_script(\"window.scrollBy(0, 250)\")  # Scroll ke bawah\n",
        "                time.sleep(2)\n",
        "\n",
        "            driver.execute_script(\"window.scrollBy(50, 0)\")  # Scroll horizontal sedikit\n",
        "            time.sleep(2)\n",
        "\n",
        "            # Ambil source HTML halaman untuk di-parsing dengan BeautifulSoup\n",
        "            soup_playstation = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "\n",
        "            # Loop untuk mengambil setiap produk dari halaman\n",
        "            for items in soup_playstation.findAll('div', class_=\"css-bk6tzz e1nlzfl2\"):\n",
        "\n",
        "                # Fungsi untuk mengambil nama produk\n",
        "                def extract_name_product():\n",
        "                    try:\n",
        "                        name_tag = items.find('div', class_='css-ouykaq')\n",
        "                        if name_tag:\n",
        "                            names_tags = name_tag.find('img')\n",
        "                            name_product = names_tags['alt'] if names_tags else \"No Name\"\n",
        "                        else:\n",
        "                            name_product = \"No Name\"\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error extracting name: {e}\")\n",
        "                        name_product = \"Error\"\n",
        "                    return name_product\n",
        "\n",
        "                # Fungsi untuk mengambil badge (contoh: official store, power merchant)\n",
        "                def extract_badge(soup):\n",
        "                    badge_map = {\n",
        "                        \"https://images.tokopedia.net/img/official_store_badge.png\": \"official store badge\",\n",
        "                        \"https://images.tokopedia.net/img/power_merchant_badge.png\": \"power merchant badge\",\n",
        "                        \"https://images.tokopedia.net/img/goldmerchant/pm_activation/badge/PM%20Pro%20Small.png\": \"gold merchant\"\n",
        "                    }\n",
        "\n",
        "                    badge_element = soup.find('div', class_='css-1hy7m5k').find('img')\n",
        "                    if badge_element:\n",
        "                        badge_src = badge_element.get('src')\n",
        "                        return badge_map.get(badge_src, \"unknown badge\")\n",
        "                    else:\n",
        "                        return \"no badge\"\n",
        "\n",
        "                # Fungsi untuk mengambil harga produk\n",
        "                def extract_price():\n",
        "                    try:\n",
        "                        prices = items.find(\"div\", class_=\"css-pp6b3e\")\n",
        "                        if prices:\n",
        "                            price_text = prices.get_text(strip=True)\n",
        "                            price = price_text.replace('Rp', '').replace('.', '')\n",
        "                            price = float(price) if price else None\n",
        "                        else:\n",
        "                            price = None\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error extracting price: {e}\")\n",
        "                        price = None\n",
        "                    return price\n",
        "\n",
        "                # Fungsi untuk mengambil rating produk\n",
        "                def extract_rating():\n",
        "                    try:\n",
        "                        rating_imgs = items.find_all(\"img\", class_=\"css-177n1u3\", alt=\"star\")\n",
        "                        ratings = len(rating_imgs)\n",
        "                        rating_value = float(ratings)\n",
        "                        rating_values = round(rating_value, 1)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error extracting rating: {e}\")\n",
        "                        rating_values = None\n",
        "                    return rating_values\n",
        "\n",
        "                # Fungsi untuk mengambil URL gambar produk\n",
        "                def extract_images():\n",
        "                    try:\n",
        "                        name_tag = items.find('div', class_='css-ouykaq')\n",
        "                        names_tags = name_tag.find('img')\n",
        "                        images = names_tags['src'] if names_tags else \"No Image\"\n",
        "                    except Exception as e:\n",
        "                        images = \"No Image\"\n",
        "                    return images\n",
        "\n",
        "                # Memanggil fungsi-fungsi ekstraksi data\n",
        "                name = extract_name_product()\n",
        "                brand = \"Sony\"\n",
        "                variant = \"PlayStation\"\n",
        "                power_badge = extract_badge(soup_playstation)\n",
        "                status_official = True jika \"official store badge\" ditemukan\n",
        "\n",
        "                # Mengambil lokasi toko dan nama toko\n",
        "                store_info = items.find(\"div\", class_=\"css-vbihp9\")\n",
        "                if store_info:\n",
        "                    location = store_info.findAll(\"span\", class_=\"css-ywdpwd\")[0].text\n",
        "                    shop_name = store_info.findAll(\"span\", class_=\"css-ywdpwd\")[1].text\n",
        "                else:\n",
        "                    location = \"Unknown\"\n",
        "                    shop_name = \"Unknown\"\n",
        "\n",
        "                price = extract_price()  # Ambil harga\n",
        "                rating = extract_rating()  # Ambil rating\n",
        "\n",
        "                # Mengambil jumlah produk yang sudah terjual\n",
        "                sold = items.find(\"div\", class_=\"css-1riykrk\")\n",
        "                if sold:\n",
        "                    span_element = sold.find(\"span\")\n",
        "                    if span_element:\n",
        "                        sold = int(span_element.text.replace('(', '').replace(')', '').strip())\n",
        "                    else:\n",
        "                        sold = None\n",
        "                else:\n",
        "                    sold = None\n",
        "\n",
        "                # Mengambil URL toko dan URL gambar produk\n",
        "                url_shop = items.select_one(\"a\").get(\"href\").replace('\"\"','')\n",
        "                url_image = extract_images()\n",
        "\n",
        "                # Menyimpan data produk ke dalam list\n",
        "                list_product_ps.append(\n",
        "                    (name, brand, variant, power_badge, status_official,\n",
        "                    location, shop_name, price, rating, sold, url_shop, url_image)\n",
        "                )\n",
        "\n",
        "            # Klik tombol halaman berikutnya jika ada\n",
        "            if ps < click_pages - 1:\n",
        "                try:\n",
        "                    next_button = driver.find_element(By.CSS_SELECTOR, \"button[aria-label^='Laman berikutnya']\")\n",
        "                    next_button.click()\n",
        "                    time.sleep(3)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error clicking next button: {e}\")\n",
        "                    break\n",
        "\n",
        "        driver.quit()  # Tutup driver setelah scraping selesai\n",
        "\n",
        "        # Buat DataFrame dari list produk\n",
        "        data_ps = pd.DataFrame(list_product_ps, columns=[\"name\", \"brand\", \"variant\", \"power_badge\",\n",
        "                                                         \"status_official\", \"location\", \"shop_name\",\n",
        "                                                         \"price\", \"rating\", \"sold\", \"url_shop\", \"url_image\"])\n",
        "\n",
        "        print(data_ps)  # Tampilkan DataFrame\n",
        "\n",
        "        return data_ps  # Return data dalam bentuk DataFrame\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "ZEfR2p0n36L6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk menyimpan data ke dalam file CSV dan JSON\n",
        "def save_data(data, url_PS):\n",
        "    # Tentukan nama file berdasarkan URL yang digunakan\n",
        "    if \"playstation\" in url_PS and \"console\" in url_PS:\n",
        "        file_name = \"console_PS\"\n",
        "    elif \"playstation\" in url_PS and \"cd-game\" in url_PS:\n",
        "        file_name = \"game_ps\"\n",
        "    else:\n",
        "        file_name = \"unknown_data\"\n",
        "\n",
        "    # Simpan data dalam format CSV\n",
        "    csv_file_name = f\"{file_name}.csv\"\n",
        "    data.to_csv(csv_file_name, index=False)\n",
        "    print(f\"Data telah disimpan ke {csv_file_name}\")\n",
        "\n",
        "    # Simpan data dalam format JSON\n",
        "    json_file_name = f\"{file_name}.json\"\n",
        "    data.to_json(json_file_name, orient=\"records\", indent=4)\n",
        "    print(f\"Data telah disimpan ke {json_file_name}\")"
      ],
      "metadata": {
        "id": "CLtZ7Oqq4EJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk menjalankan scraping secara multithreaded\n",
        "def run_multithreaded_scraping(urls):\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        results = list(executor.map(playstation, urls))\n",
        "\n",
        "    # Simpan setiap hasil scraping ke dalam file\n",
        "    for data, url in zip(results, urls):\n",
        "        if data is not None:\n",
        "            save_data(data, url)\n",
        "\n",
        "# Main function untuk menjalankan program\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    urls = [url_console_playstation, url_game_playstation]\n",
        "    run_multithreaded_scraping(urls)  # Jalankan scraping dengan multithreading"
      ],
      "metadata": {
        "id": "fqiLFm1i4QL8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}